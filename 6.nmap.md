## Tool invocation and workflow writing

At Leviathan Platform, all projects are divided into two types.

* Self-use tool package
* Package or workflow for external invocation

In the previous step, after initializing the helloworld project, you can start to code in a new file. This is a self-use package. You can freely design the directory structure of the project. However, **if you want the package to be used by others, meaning it can be invoked externally, a standardized project structure must be established in accordance with the rules of Leviathan Platform**:

```bash
<username>.<tool>/lev/<username>/<tool>
```


Tool invocation and programming first requires the configuration of pre-dependent environment. If the above steps have not been completed, please read the [environment configuration] (#Development environment configuration)section. Also, please read the [certificate uploading and acquisition] (#certificate uploading and acquisition)module, and then you can build workspaces, invoke tools and write workflows.


* Invoke Tool: Enable the Docker image that encapsulates the complete tool, and pass the set parameters and commands that are to be executed into the image. Process the results generated by the previously defined functions and save them to the MongoDB program (see [Docker usage](https://docs.docker.com/get-started/)  for details here).
* Write Workflow: Decide how the tool will be used (such as what mode to run in, which parameter commands to pass in) and how the resulting data will be delivered and used.

As a port scanning tool known to everyone in the cyber security industry, Nmap will be used as an example below to build a package.

There are three python files in this project:

* \__init__.py				    _init_.py initialization file, responsible for importing modules
* asset.py                       asset.py workflow file, responsible for module workflow
* nmap.py                 nmap.py module specific mode or function implementation code


### Package construction

1. First, create a workspace directory locally, such as `./nmap_python`；

   ```bash
   $ mkdir nmap_python
   ```



2. Go to `./nmap_python` and execute the configuration file installation command. For details on obtaining the levhub-token, see [SDK Credential Obtaining](#SDK Credential Obtaining):


   ```bash
   $ cd nmap_python
   # Configure the levhub-token of Leviathan system SDK as a global variable. It is recommended to put it in the system configuration file, otherwise it will disappear after reopening the terminal, and needs to be re-imported every time when a new project is built.
   $ export LEVHUB_TOKEN=your levhub-token
   
   # szczecin can be replaced with your own community user name, nmap_python is the name of the tool to be uploaded.
   $ pdm lev new szczecin.nmap_python 
   $ cd ./szczecin.nmap_python
   
   # Install levrt, bs4 packages under username.tool/ directory
   # bs4 is the dependency package to be refered by the following example
   $ pdm add levrt bs4
   ```



* In the `szczecin.nmap_python` directory, you can get the configuration files `.pdm.toml`、`pyproject.toml` levrt dependency package `__pypackages__`, and the directory structure `lev/szczecin/nmap_python`;


3. The final package directory structure is as follows, and some files need to be created manually:

```shell
./lev-hub/
└── szczecin.nmap_python/
    ├── .gitignore
    ├── lev/						# Projects for external invocations must have this directory structure and must be named as lev
    │   └── szczecin/				# The project for external invocation must have this directory structure, the user name of Leviathan platform
    │       └── nmap_python/		# Projects for external invocation must have this directory structure, tool name
    │           ├── nmap.py	# Manual creation, it is the tool.py described above, the specific mode of the module or the implementation function code
    │           └── __init__.py		# Projects for external calls must have this file, initialization file, responsible for importing modules
    ├── pdm.lock						
    ├── .pdm.toml
    ├── __packages__					#  The folder where python-related dependencies are stored
     └── pyproject.toml
    └── pyproject.toml
  ...
```







### Basic invocations of tools

We have already introduced the basic package structure above. Here is the description of the files in the package. A complete project contains at least one of the following`__init__.py` files:

* `__init__.py`            #  Necessary file
* `tool.py`                #  non-essential file, the name is irrelevant, and usually named as the tool name, such as nmap.py

Let’s start with tool.py, taking the simplest modeless invocation to nmap as an example:

#### Introduction of tool.py

tool.py is not a fixed name, it refers to all python files that encapsulate tool invocation functions.

##### Modeless invocation

The so-called modeless invocation means that in the tool invocation file, only one command is encapsulated and only one function is included.

Please **strictly follow the following code format, do not omit any comments or parameters** to prevent the invocation from failing.

The following is an example of uploading the nmap_python tool:

1.Before writing the `nmap.py` file, you need to read the relevant contents of `image management`. Then you should upload the build file (i.e., Dockerfile of the tool image to be invoked) to the bound Github repository. This allows Leviathan to automatically build the image, get the image name and version number. (.username.tool:tag), such as `.szczecin.nmap_python:v1.0`;
 
2. Start writing `nmap.py`

   In this example, a command of Nmap is encapsulated as a modeless tool. The command is as follows:
   
   `nmap -PE -sn -T4 -n -oX /tmp/alive.xml ip`

   Write the brief overview of the tools at the beginning of the code [(Note 2)](https://github.com/talentsec/lev_doc/blob/main/14.%20FAQ-en.md#why-should-developers-write-a-series-of-comments-within-tools-and-workflows)

   The overview including the introduction of the tool, the name (desc) and the [tool type (cats)](https://github.com/talentsec/lev_doc/blob/main/14.%20FAQ-en.md#appendix-list-of-tool-classifications-in-chinese-and-english) etc. are written before the function. nmap_python is defined as a complete function mode.

   **The contents after # in the following code are all code descriptions, which cannot be directly copied or pasted into the code file:**：

   ~~~python
   # The following content is an introduction to the tool and cannot be omitted
   """
   nmap is a free and open source program for network discovery and security auditing, used for tasks such as network scanning, service upgrade plan management, and host or service uptime monitoring.
   By using raw IP packets to determine the hosts available on the network, the services provided by those hosts (application name and version), the operating system information they are running on, the type of packet filter/firewall, etc.
   The nmap_python image contains the real-time updated binary version of nmap, and is equipped with a python environment to update the nmap-os-db file in real time.
   """
   # Import tool dependency packages, which are used to launch tool mirroring, write result data to database, rewrite ENTRYPOINT and parse comments.
   from levrt import Cr, ctx, remote, annot
   
   # Using the annot decorator to introduce and give examples of this method and params (parameters)
   # holder is an example of parameter ip
   @annot.meta(desc="nmap ICMP loopback message to determine host survival", params=[annot.Param("ip", "target ip or ip segment to scan", holder="192.168.1.1/24") ])
   def alive(ip: str) -> Cr: # Note that the parameter type of each parameter needs to be specified when defining the mode
       """
       nmap ICMP loopback message to determine the host is alive
       ```
       await nmap.alive("192.168.1.1/24")
       ```
       """
       @remote
       def entry(ip):
           import subprocess
           # In the docker environment, you need to add additional paths, otherwise the code will prompt that the bs4 module cannot be found. If you also add custom dependencies in other projects, you also need to add these codes.
           import sys
           sys.path.append("/usr/local/lib/python3.10/site-packages")
           from bs4 import BeautifulSoup
           # Execute the command, because the system.run() function has the risk of injection, so use the subprocess.run() method here.
           subprocess.run(['nmap', '-PE', '-sn', '-T4', '-n', '-oX', '/tmp/alive.xml', ip])
           # The following is the data processing code, which can be ignored.
           soup = BeautifulSoup(open('/tmp/alive.xml', 'r').read(), 'html.parser')
           ip_alive = {
               'target': ip,
               'alive': []
               }
           if soup.host:
               for host in soup.find_all('host'):
                   if host.status['state'] == 'up':
                       live = host.address['addr']
                       ip_alive['alive'].append(live)
           # store in mongo database
           ctx.update(ip_alive)
       # "registry.cn-hangzhou.aliyuncs.com/levkit/nmap_python:v1.0" is the image address to run the code, image URL + image name + image version.
       # "szczecin/nmap_python.alive@1.0"  is the namespace stored in mongo
       return Cr("registry.cn-hangzhou.aliyuncs.com/levkit/nmap_python:v1.0", "szczecin/nmap_python.alive@1.0", entry=entry(ip), host=True)
   
   ~~~
   
    The entry( ) method in the code will overwrite the ENTRYPOINT [ ] used in the Dockerfile when the original tool image container is built [(Note4)](https://github.com/talentsec/lev_doc/blob/main/14.%20FAQ-en.md#will-entry-override-entrypoint)
   
    In the entry( ) method, developers can specify how the tool image should execute the command after receiving the parameters, and how to process the outgoing result data :[(Note5)](https://github.com/talentsec/lev_doc/blob/main/14.%20FAQ-en.md#how-will-tools-output-data-be-processed)：
   
    Finally, when the raw() method returns, the `registry.cn-hangzhou.aliyuncs.com/levkit/nmap_python:v1.0`  image will be enabled by using the Cr( ) method, and the command and output defined by the entry( ) method will be executed in the container Process, and finally pass the data into the  `szczecin/nmap_python.alive@1.0` space of mongodb [(Note6)](https://github.com/talentsec/lev_doc/blob/main/14.%20FAQ-en.md#how-to-specify-the-location-for-the-tool-output-results-to-store):



3. At this point, a modeless tool invocation is completed. There is only one alive() function in the entire tool.py (i.e. nmap.py) file, so it is called modeless.

   If IDE reports an error, indicating that the dependent packages levrt and bs4 cannot be found, please follow the prompts in the `Development Environment Configuration` section above to configure the corresponding python IDE.
   


4. The indispensable comments in the code above will appear in the following positions on Leviathan (if the tool goes throught the official review and is published):

   ![code comments.jpg](https://levimg.s3.cn-northwest-1.amazonaws.com.cn/x/cd88059f-e2c1-4bb9-91aa-8963340bf408.JPEG)

5. `@annot.meta` parameter description is as follows:

   | Parameter name       | Parameter type                     | Parameter description       | Parameter example                                                     |
   | ------------ | ----------------------------- | -------------- | ------------------------------------------------------------ |
   | desc         | str                           | Mode (method) description | "nmap SYN scans the target host for open ports, host names and operating systems"             |
   | params       | \[annot.Param...] (list type) | Mode call parameters | [annot.Param("ip", "target ip or ip segment to scan", holder="192.168.1.1/24")] |
   | Param.holder | str                           | Parameter example      | ”192.168.1.1/24"                                             |

#### Upload

If you are trying to complete the demo above, you need to create a  `__init__`.py file in the directory, and write the following code in the `__init__.py` file:

```python
from levrt import annot
from .nmap_python import alive
# Export the tool here, please refer to the following chapter for details.
__lev__ = annot.meta([alive])
```



Then you can upload to Leviathan platform and execute the following commands in the `szczecin.nmap_python/` directory:

```bash
$ pdm lev upload
```

If an error is reported:

```python
error: levhub credentials needed
```

Then it is very likely that you did not put the system environment variable when you executed the `export LEVHUB_TOKEN=your levhub-token` command earlier, and you need to import it again.

If you just want to invoke the tool written by yourself, you can invoke it directly by referring to the writing method in chapter `4. Hello World`.

#### Run

If you want to run it on Leviathan, you may need to package the image yourself:

```python
FROM python:3.10-alpine3.14

WORKDIR /root/
# Modify the source of pip in docker
RUN pip install -U pip
RUN pip config set global.index-url http://mirrors.aliyun.com/pypi/simple
RUN pip config set install.trusted-host mirrors.aliyun.com
#  Modify the source of the apk add command in docker
RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories
# Manually add nmap and pip to install bs4 dependencies
# Please note that the previous execution of pdm add bs4 just added the bs4 dependency locally, but it is not installed in the docker environment, so it needs to be installed when building the docker image.
RUN apk add nmap && pip install bs4
```

Follow the process to start building the image, then replace the image name `registry.cn-hangzhou.aliyuncs.com/levkit/nmap_python:v1.0` in the code above with your own packaged image name and version, and upload it to Leviathan platform. In `Warehouse`-> `My Tools`, you can create new tasks

In the end the result will be:

```json
{
  "data": [
    {
      "_id": {
        "job": 27,
        "task": 0
      },
      "alive": [
        "192.168.1.1",
        "192.168.1.28",
        "192.168.1.38",
        "192.168.1.70",
        "192.168.1.105",
        "192.168.1.173",
        "192.168.1.202",
        "192.168.1.221",
        "192.168.1.237"
      ],
      "target": "192.168.1.1/24"
    }
  ]
}
```


